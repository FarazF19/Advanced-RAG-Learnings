{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41c6a3e1",
   "metadata": {},
   "source": [
    "# Query Transformations\n",
    "Query transformations are a set of approaches focused on re-writing and / or modifying questions for retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a5e428",
   "metadata": {},
   "source": [
    "![Alt text](query_transform.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ee5bcd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7a9bd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_PROJECT'] = 'advanced-rag'\n",
    "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc12ad33",
   "metadata": {},
   "source": [
    "# Part 1: Multi Query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4d375e",
   "metadata": {},
   "source": [
    "![Alt text](multi_query.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Docs:\n",
    "\n",
    "https://python.langchain.com/docs/modules/data_connection/retrievers/MultiQueryRetriever\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ccc0aa",
   "metadata": {},
   "source": [
    "### Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90c497cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### INDEXING ####\n",
    "\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "blog_docs = loader.load()\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300, \n",
    "    chunk_overlap=50)\n",
    "\n",
    "# Make splits\n",
    "splits = text_splitter.split_documents(blog_docs)\n",
    "\n",
    "# Index\n",
    "model_name = \"BAAI/bge-small-en\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "hf_embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    ")\n",
    "vectorstore = FAISS.from_documents(documents=splits, \n",
    "                                    embedding=hf_embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4cad9e",
   "metadata": {},
   "source": [
    "### Multi Query Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573155df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Multi Query: One Question, Multiple Perspectives.\n",
    "\n",
    "template=\"\"\"\n",
    "You are an AI language model assistant. Your task is to generate five \n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
    "\n",
    "\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "generate_queries=(prompt_perspectives | ChatGroq(model=\"openai/gpt-oss-120b\", temperature=0)|StrOutputParser()| (lambda x: x.split(\"\\n\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16e9cdd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What does the term “task decomposition” mean?  ',\n",
       " 'How is task decomposition defined in the context of problem solving?  ',\n",
       " 'Can you explain the concept of breaking a task into sub‑tasks?  ',\n",
       " 'What are the principles and steps involved in task decomposition?  ',\n",
       " 'In which fields is task decomposition used and why is it important?']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_queries.invoke(\"What is Task Decomposition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d397d306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HAROON TRADERS\\AppData\\Local\\Temp\\ipykernel_9560\\3066567925.py:14: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  return [loads(doc) for doc in unique_docs]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Unique documents only to avoid duplicates to be retrieved\n",
    "\n",
    "from langchain.load import dumps, loads\n",
    "\n",
    "def get_unique_union(documents: list[list]):\n",
    "    \"\"\" Unique union of retrieved docs \"\"\"\n",
    "    # Flatten list of lists, and convert each Document to string\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "\n",
    "    # Get unique documents\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "\n",
    "    # Return\n",
    "    return [loads(doc) for doc in unique_docs]\n",
    "\n",
    "# Retrieve\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
    "docs = retrieval_chain.invoke({\"question\":question})\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d05138c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Task decomposition** is the process by which an LLM‑based autonomous agent breaks a large, complex request into a series of smaller, manageable sub‑tasks (or sub‑goals) that can be solved step‑by‑step.  \\n\\nKey points:\\n\\n| Aspect | Description |\\n|--------|-------------|\\n| **Purpose** | Turns a “big” problem into a sequence of simpler actions, making planning, execution, and error‑recovery easier for the agent. |\\n| **Techniques** | • **Chain‑of‑Thought (CoT)** prompting – ask the model to “think step‑by‑step” so it explicitly lists intermediate steps.<br>• **Tree‑of‑Thought (ToT)** – generate multiple possible thoughts at each step and search (BFS/DFS) among them, allowing exploration of alternative solution paths.<br>• **Prompt‑driven instructions** – e.g., “What are the subgoals for achieving X?” or “List the steps for Y.” |\\n| **Implementation** | The LLM receives a prompt that requests a decomposition (often in a numbered list). The output can be used directly as a task queue, or fed into a higher‑level planner that assigns each sub‑task to an expert model/tool. |\\n| **Benefits** | • Improves reasoning depth by allocating more compute to each micro‑task.<br>• Provides a clear execution order and dependency graph (useful for multi‑modal pipelines).<br>• Enables self‑reflection and re‑planning when a sub‑task fails. |\\n| **Typical workflow** | 1. **User request** → LLM receives the request.<br>2. **Decomposition prompt** → LLM generates a list of sub‑tasks (task type, ID, dependencies, arguments).<br>3. **Task assignment** → Each sub‑task may be routed to a specialized model/tool.<br>4. **Execution** → Sub‑tasks are run sequentially or in parallel, with results fed back for further planning. |\\n\\nIn short, task decomposition is the “divide‑and‑conquer” step in LLM‑powered agents that transforms a high‑level goal into concrete, ordered actions that the system can reliably plan, execute, and monitor.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "llm= ChatGroq(model=\"openai/gpt-oss-120b\", temperature=0)\n",
    "\n",
    "rag_chain= ({\"context\":retrieval_chain,\"question\":itemgetter(\"question\")} | prompt | llm  | StrOutputParser())\n",
    "\n",
    "\n",
    "rag_chain.invoke({\"question\":question})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105aac37",
   "metadata": {},
   "source": [
    "# Part 2: RAG-Fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78f4daf",
   "metadata": {},
   "source": [
    "![Alt text](RAG_Fusion.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da557a1d",
   "metadata": {},
   "source": [
    "### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "752c4d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# RAG-Fusion: Related\n",
    "template = \"\"\"You are a helpful assistant that generates multiple search queries based on a single input query. \\n\n",
    "Generate multiple search queries related to: {question} \\n\n",
    "Output (4 queries):\"\"\"\n",
    "\n",
    "prompt_rag_fusion = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a43ef68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_rag_fusion \n",
    "    | ChatGroq(model=\"openai/gpt-oss-20b\", temperature=0)\n",
    "    | StrOutputParser() \n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e398696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. “Task decomposition in large language model agents: definition and key concepts”  ',\n",
       " '2. “How do LLM agents perform task decomposition? Step‑by‑step examples”  ',\n",
       " '3. “Benefits of task decomposition for autonomous LLM agents”  ',\n",
       " '4. “Implementing task decomposition in LLM‑based agents: code snippets and best practices”']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_queries.invoke(\"What is Task Decomposition for LLM agents?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea80733",
   "metadata": {},
   "source": [
    "# RRF Explanation\n",
    "\n",
    "## Question Rankings\n",
    "- **Question A**  \n",
    "  1. Doc1  \n",
    "  2. Doc4  \n",
    "  3. Doc3  \n",
    "  4. Doc2  \n",
    "\n",
    "- **Question B**  \n",
    "  1. Doc3  \n",
    "  2. Doc1  \n",
    "  3. Doc2  \n",
    "  4. Doc4  \n",
    "\n",
    "- **Question C**  \n",
    "  1. Doc4  \n",
    "  2. Doc3  \n",
    "  3. Doc1  \n",
    "  4. Doc2  \n",
    "\n",
    "---\n",
    "\n",
    "## Rank Positions\n",
    "- **Doc1**  \n",
    "  - Question A rank: **1**  \n",
    "  - Question B rank: **2**  \n",
    "  - Question C rank: **3**  \n",
    "\n",
    "- **Doc2**  \n",
    "  - Question A rank: **4**  \n",
    "  - Question B rank: **3**  \n",
    "  - Question C rank: **4**  \n",
    "\n",
    "- **Doc3**  \n",
    "  - Question A rank: **3**  \n",
    "  - Question B rank: **1**  \n",
    "  - Question C rank: **2**  \n",
    "\n",
    "- **Doc4**  \n",
    "  - Question A rank: **2**  \n",
    "  - Question B rank: **4**  \n",
    "  - Question C rank: **1**  \n",
    "\n",
    "---\n",
    "\n",
    "## Reciprocal Rank Fusion Calculation\n",
    "\n",
    "![Alt text](RRF.png)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Final Ranking\n",
    "1. **Doc1** ≈ 0.0487  \n",
    "2. **Doc3** ≈ 0.0487  \n",
    "3. **Doc4** ≈ 0.0484  \n",
    "4. **Doc2** ≈ 0.0469  \n",
    "\n",
    "---\n",
    "\n",
    "✅ **Conclusion**: Both **Doc1** and **Doc3** achieve the highest RRF scores, making them the most relevant across the question rankings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39ffbc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\" Reciprocal_rank_fusion that takes multiple lists of ranked documents \n",
    "        and an optional parameter k used in the RRF formula \"\"\"\n",
    "    \n",
    "    # Initialize a dictionary to hold fused scores for each unique document\n",
    "    fused_scores = {}\n",
    "\n",
    "    # Iterate through each list of ranked documents\n",
    "    for docs in results:\n",
    "        # Iterate through each document in the list, with its rank (position in the list)\n",
    "        for rank, doc in enumerate(docs):\n",
    "            # Convert the document to a string format to use as a key (assumes documents can be serialized to JSON)\n",
    "            doc_str = dumps(doc)\n",
    "            # If the document is not yet in the fused_scores dictionary, add it with an initial score of 0\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            # Retrieve the current score of the document, if any\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            # Update the score of the document using the RRF formula: 1 / (rank + k)\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    # Sort the documents based on their fused scores in descending order to get the final reranked results\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "\n",
    "    # Return the reranked results as a list of tuples, each containing the document and its fused score\n",
    "    return reranked_results\n",
    "\n",
    "retrieval_chain_rag_fusion = generate_queries | retriever.map() | reciprocal_rank_fusion\n",
    "docs = retrieval_chain_rag_fusion.invoke({\"question\": question})\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0018c263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Task decomposition** is the process by which an LLM‑driven autonomous agent breaks a large, complex request into a series of smaller, manageable sub‑tasks (or sub‑goals) that can be solved step‑by‑step.  \\n\\nKey points from the Lilian\\u202fWeng article:\\n\\n| Aspect | Description |\\n|--------|-------------|\\n| **Purpose** | Enables the agent to handle complicated problems that would be too difficult to solve in a single pass. By creating intermediate milestones, the agent can plan ahead, track progress, and recover from errors. |\\n| **How it’s done** | • **Prompt‑based prompting** – simple instructions such as “Steps for\\u202fXYZ.\\u202f1.” or “What are the subgoals for achieving\\u202fXYZ?” can coax the LLM to list sub‑tasks. <br>• **Chain‑of‑Thought (CoT)** – the model is asked to “think step‑by‑step,” which naturally yields a linear decomposition of the problem. <br>• **Tree‑of‑Thought (ToT)** – extends CoT by generating multiple candidate thoughts at each step and organizing them into a search tree (BFS/DFS) that can be evaluated by a classifier or majority vote. |\\n| **Typical workflow** | 1. **Planning stage** – the LLM receives the user request and, using CoT/ToT or explicit prompts, outputs a list of sub‑goals with identifiers and dependencies. <br>2. **Execution stage** – each sub‑goal is handed to the appropriate tool or “expert” module (e.g., a calculator, a retrieval system, a code generator). <br>3. **Reflection/Refinement** – after completing a sub‑goal the agent can self‑criticize and adjust later steps if needed. |\\n| **Benefits** | • Reduces the cognitive load on the model (the LLM only needs to reason about a small piece at a time). <br>• Provides a clear execution order and makes it easier to parallelize or delegate tasks to specialized modules. <br>• Facilitates self‑reflection and error correction because the agent can compare the outcome of each sub‑task against its plan. |\\n| **Challenges** | • Limited context windows can truncate earlier sub‑goals, so the decomposition must be compact or stored externally (e.g., in a vector store). <br>• The LLM must reliably generate correct arguments for each sub‑task; otherwise downstream tools may fail. |\\n\\nIn short, **task decomposition** is the LLM’s strategy of turning a big problem into a structured set of smaller, ordered sub‑tasks—often using “think‑step‑by‑step” prompting techniques like Chain‑of‑Thought or Tree‑of‑Thought—so that the autonomous agent can plan, execute, and reflect more effectively.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain_rag_fusion, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e15be3",
   "metadata": {},
   "source": [
    "# Part 3:Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24bbac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Decomposition\n",
    "template = \"\"\"You are a helpful assistant that generates multiple sub-questions related to an input question. \\n\n",
    "The goal is to break down the input into a set of sub-problems / sub-questions that can be answers in isolation. \\n\n",
    "Generate multiple search queries related to: {question} \\n\n",
    "Output (3 queries):\"\"\"\n",
    "\n",
    "prompt_decomposition = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a707949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LLM\n",
    "llm = ChatGroq(model=\"llama-3.3-70b-versatile\", temperature=0)\n",
    "\n",
    "# Chain\n",
    "generate_queries_decomposition = ( prompt_decomposition | llm | StrOutputParser() | (lambda x: x.split(\"\\n\")))\n",
    "\n",
    "# Run\n",
    "question = \"What are the main components of an LLM-powered autonomous agent system?\"\n",
    "\n",
    "questions = generate_queries_decomposition.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "974eb8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['To break down the question \"What are the main components of an LLM-powered autonomous agent system?\" into manageable sub-questions, we can consider the following search queries:',\n",
       " '',\n",
       " '1. **What are the key architectural elements of an autonomous agent system?**',\n",
       " '   - This query focuses on understanding the overall structure and fundamental parts that make up an autonomous agent system, which can include perception, decision-making, and action components.',\n",
       " '',\n",
       " \"2. **How does a Large Language Model (LLM) integrate with an autonomous agent's decision-making process?**\",\n",
       " '   - This search query delves into the specifics of how LLMs contribute to the autonomous decision-making process, potentially exploring aspects like natural language processing, knowledge graph integration, and reasoning mechanisms.',\n",
       " '',\n",
       " '3. **What role do sensing and perception components play in an LLM-powered autonomous agent, and how do they interact with the LLM?**',\n",
       " '   - This query investigates the input side of the autonomous agent, examining how the system gathers information from its environment and how this information is processed and utilized by the LLM to make informed decisions.',\n",
       " '',\n",
       " 'These sub-questions can help in understanding the complex interactions within an LLM-powered autonomous agent system by isolating key components and their functionalities.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fc4b3c",
   "metadata": {},
   "source": [
    "Recursive \n",
    "\n",
    "![Alt text](Decomposition.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6732911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "template = \"\"\"Here is the question you need to answer:\n",
    "\n",
    "\\n --- \\n {question} \\n --- \\n\n",
    "\n",
    "Here is any available background question + answer pairs:\n",
    "\n",
    "\\n --- \\n {q_a_pairs} \\n --- \\n\n",
    "\n",
    "Here is additional context relevant to the question: \n",
    "\n",
    "\\n --- \\n {context} \\n --- \\n\n",
    "\n",
    "Use the above context and any background question + answer pairs to answer the question: \\n {question}\n",
    "\"\"\"\n",
    "\n",
    "decomposition_prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32067c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def format_qa_pair(question, answer):\n",
    "    \"\"\"Format Q and A pair\"\"\"\n",
    "    \n",
    "    formatted_string = \"\"\n",
    "    formatted_string += f\"Question: {question}\\nAnswer: {answer}\\n\\n\"\n",
    "    return formatted_string.strip()\n",
    "\n",
    "# llm\n",
    "llm = ChatGroq(model=\"llama-3.3-70b-versatile\", temperature=0, max_tokens=512)\n",
    "\n",
    "\n",
    "q_a_pairs = \"\"\n",
    "for q in questions:\n",
    "    \n",
    "    rag_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | retriever, \n",
    "     \"question\": itemgetter(\"question\"),\n",
    "     \"q_a_pairs\": itemgetter(\"q_a_pairs\")} \n",
    "    | decomposition_prompt\n",
    "    | llm\n",
    "    | StrOutputParser())\n",
    "\n",
    "    answer = rag_chain.invoke({\"question\":q,\"q_a_pairs\":q_a_pairs})\n",
    "    q_a_pair = format_qa_pair(q,answer)\n",
    "    q_a_pairs = q_a_pairs + \"\\n---\\n\"+  q_a_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63440bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## 3.\\u202fLLM‑Based Autonomous Agent System Building Blocks  \\n\\nBelow is a concise, modular view of the **building blocks** that compose a modern autonomous agent whose core controller is a Large Language Model (LLM).  \\nThe list is organized as a *layered architecture* (perception → cognition → action → learning → governance) and is directly derived from the survey by Lilian\\u202fWeng (2023) and the component‑level answer in the background material.\\n\\n| # | Building Block | Core Responsibility | Typical Implementation / Example | Why It Matters |\\n|---|---------------|-------------------|--------------------------------|---------------|\\n| **1** | **LLM Core (Brain)** | Generates plans, decisions, natural‑language responses, and code. | GPT‑4, Claude‑3, Llama‑2‑70B, etc. | The “brain” that drives all other blocks. |\\n| **2** | **Perception / Input Processing** | Converts raw sensory data (text, images, sensor streams) into a format the LLM can consume. | OCR, CLIP, image captioning, sensor‑to‑text adapters. | Provides the agent with situational awareness. |\\n| **3** | **Memory / Knowledge Base** | Stores short‑term context and long‑term facts/experiences for future reasoning. | Working‑memory buffer + retrieval‑augmented memory (vector store, Pinecone, FAISS). | Enables continuity, learning, and context‑aware reasoning. |\\n| **4** | **Planning & Goal‑Decomposition** | Breaks high‑level goals into actionable sub‑goals and sequences. | Prompt‑based planners, Tree‑of‑Thoughts, Chain‑of‑Thought, external symbolic planners. | Turns vague objectives into concrete steps. |\\n| **5** | **Decision‑Making / Reasoning** | Generates, evaluates, and refines plans (self‑reflection, hindsight chains). | Self‑reflection prompts, RLHF, hindsight chain. | Improves plan quality and robustness. |\\n| **6** | **Tool/Action Interface** | Executes concrete actions (API calls, code execution, web browsing, robotics). | LangChain, OpenAI tool‑calling API, custom SDKs. | Bridges the LLM to the real world. |\\n| **7** | **Reflection / Self‑Critique** | Evaluates outcomes, learns from mistakes, refines future plans. | Self‑evaluation prompts, hindsight chain, RLHF. | Drives continuous improvement. |\\n| **8** | **Safety & Governance Layer** | Enforces constraints, ethics, compliance, sandboxing. | System messages, policy prompts, rate‑limits, sandboxing. | Prevents harmful or unintended behavior. |\\n| **9** | **Feedback Loop** | Monitors outcomes, triggers replanning, updates memory. | Event‑driven architecture, message queues, reactive loops. | Keeps the agent adaptive and responsive. |\\n| **10** | **User Interface / Interaction Layer** | Handles user queries, clarifications, and dialogue. | Chat UI, voice assistants, dashboards. | Provides the human‑agent interaction channel. |\\n| **11** | **Monitoring & Logging** | Tracks performance, logs actions, aids debugging. | Structured logs, dashboards, audit trails. | Enables observability and auditability. |\\n\\n---\\n\\n### How the Blocks Interact (Typical Execution Cycle)\\n\\n1. **Goal Reception** – User or environment supplies a high‑level goal.  \\n2. **Perception** extracts relevant context.  \\n3. **Planning** decomposes the goal into a sub‑goal tree.  \\n4. **Execution Loop** (for each sub‑goal):  \\n   * Perception → gather data.  \\n   * Tool/Action Interface → invoke API or run code.  \\n   * Memory Update → store results.  \\n   * Reflection → evaluate success, adjust plan.  \\n   * Safety & Governance → check constraints.  \\n5. **Feedback & Learning** – Memory stores outcomes; Reflection refines future plans.  \\n6. **Monitoring** logs actions for debugging and audit.  \\n7. **User Interaction** – UI handles clarifications or new goals.\\n\\n---\\n\\n### Representative Projects & Papers\\n\\n| Project | Core Idea | Key Building Blocks |\\n|--------|----------|--------------------|\\n| **AutoGPT** | LLM‑driven autonomous agent | System messages, format parsing, tool‑calling |\\n| **GPT‑Engineer** | Code‑generation agent | Prompt‑based planning, code execution |\\n| **Generative Agents** | Simulated human agents | Memory, perception, planning, reflection |\\n| **Reflexion** | Dynamic memory + self‑reflection | Retrieval‑augmented memory, hindsight chain |\\n| **MRKL** | Modular neuro‑symbolic system | LLM router + expert modules (calculator, API) |\\n\\n---\\n\\n### Take‑aways\\n\\n* The **LLM core** is the central decision‑maker; all other blocks provide the *inputs*, *execution*, *learning*, and *governance* that make the agent autonomous.  \\n* **Memory** and **planning** are the pillars that give the agent continuity and the ability to tackle complex tasks.  \\n* **Tool interfaces** and **reflection** turn the LLM’s textual output into real‑world actions and learning.  \\n* **Safety** and **monitoring** are non‑negotiable for responsible deployment.  \\n\\nThese building blocks form the foundation for any LLM‑based autonomous agent system.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107fcb3d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![Alt text](Decomposition_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01a00e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer each sub-question individually \n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# RAG prompt\n",
    "prompt_rag = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def retrieve_and_rag(question,prompt_rag,sub_question_generator_chain):\n",
    "    \"\"\"RAG on each sub-question\"\"\"\n",
    "    \n",
    "    # Use our decomposition / \n",
    "    sub_questions = sub_question_generator_chain.invoke({\"question\":question})\n",
    "    \n",
    "    # Initialize a list to hold RAG chain results\n",
    "    rag_results = []\n",
    "    \n",
    "    for sub_question in sub_questions:\n",
    "        \n",
    "        # Retrieve documents for each sub-question\n",
    "        retrieved_docs = retriever.get_relevant_documents(sub_question)\n",
    "        \n",
    "        # Use retrieved documents and sub-question in RAG chain\n",
    "        answer = (prompt_rag | llm | StrOutputParser()).invoke({\"context\": retrieved_docs, \n",
    "                                                                \"question\": sub_question})\n",
    "        rag_results.append(answer)\n",
    "    \n",
    "    return rag_results,sub_questions\n",
    "\n",
    "# Wrap the retrieval and RAG process in a RunnableLambda for integration into a chain\n",
    "answers, questions = retrieve_and_rag(question, prompt_rag, generate_queries_decomposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234632ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Main Components of an LLM‑Powered Autonomous Agent System**\\n\\n| # | Component | Core Responsibility | Typical Sub‑modules / Techniques |\\n|---|----------|-------------------|--------------------------------|\\n| **1. LLM Core** | Acts as the “brain” – generates text, decisions, and high‑level plans. | Prompt‑engineering, chain‑of‑thought, Tree‑of‑Thoughts, ReAct, etc. |\\n| **2. Planning & Reflection** | Breaks tasks into sub‑goals, refines actions, and self‑criticises. | Sub‑goal decomposition, self‑reflection loops, policy‑updates. |\\n| **3. Memory** | Stores short‑term context and long‑term knowledge for retrieval and updating. | Episodic memory, vector‑store, knowledge graph, retrieval‑augmented generation. |\\n| **4. Tool / Interface Layer** | Enables the agent to interact with the outside world (APIs, web, code, hardware). | Tool routers (MRKL, Toolformer), API calls, web‑browser, code‑execution, hardware control. |\\n\\nThese four pillars—**LLM core, planning & reflection, memory, and tool integration**—form the modular architecture that powers most contemporary autonomous agents such as AutoGPT, GPT‑Engineer, and generative agents.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_qa_pairs(questions, answers):\n",
    "    \"\"\"Format Q and A pairs\"\"\"\n",
    "    \n",
    "    formatted_string = \"\"\n",
    "    for i, (question, answer) in enumerate(zip(questions, answers), start=1):\n",
    "        formatted_string += f\"Question {i}: {question}\\nAnswer {i}: {answer}\\n\\n\"\n",
    "    return formatted_string.strip()\n",
    "\n",
    "context = format_qa_pairs(questions, answers)\n",
    "\n",
    "# Prompt\n",
    "template = \"\"\"Here is a set of Q+A pairs:\n",
    "\n",
    "{context}\n",
    "\n",
    "Use these to synthesize an answer to the question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"context\":context,\"question\":question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d6b521",
   "metadata": {},
   "source": [
    "# Part 4:Step Back"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf826f40",
   "metadata": {},
   "source": [
    "![image.png](step_back.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62755945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few Shot Examples\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"Could the members of The Police perform lawful arrests?\",\n",
    "        \"output\": \"what can the members of The Police do?\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Jan Sindel’s was born in what country?\",\n",
    "        \"output\": \"what is Jan Sindel’s personal history?\",\n",
    "    },\n",
    "]\n",
    "# We now transform these to example messages\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an expert at world knowledge. Your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer. Here are a few examples:\"\"\",\n",
    "        ),\n",
    "        # Few shot examples\n",
    "        few_shot_prompt,\n",
    "        # New question\n",
    "        (\"user\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbe86791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How do complex tasks get broken down into simpler ones?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_queries_step_back = prompt | ChatGroq(model=\"llama-3.3-70b-versatile\", temperature=0) | StrOutputParser()\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "generate_queries_step_back.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db6b26b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex tasks into smaller, more manageable sub-tasks or sub-goals. This is a crucial component of planning in LLM-powered autonomous agents, as it enables the agent to efficiently handle complex tasks by dividing them into simpler, more manageable steps.\\n\\nThere are several approaches to task decomposition for LLM agents, including:\\n\\n1. **Chain of Thought (CoT)**: This involves instructing the LLM to \"think step by step\" and decompose complex tasks into smaller, simpler steps. CoT transforms big tasks into multiple manageable tasks and provides insight into the model\\'s thinking process.\\n2. **Tree of Thoughts**: This extends CoT by exploring multiple reasoning possibilities at each step, creating a tree structure. The search process can be breadth-first search (BFS) or depth-first search (DFS) with each state evaluated by a classifier or majority vote.\\n3. **Simple Prompting**: LLM can be prompted with simple questions like \"Steps for XYZ\" or \"What are the subgoals for achieving XYZ?\" to decompose tasks.\\n4. **Task-specific Instructions**: Using task-specific instructions, such as \"Write a story outline\" for writing a novel, can also help with task decomposition.\\n5. **Human Inputs**: Task decomposition can also be done with human inputs, where humans provide guidance on how to break down complex tasks.\\n\\nTask decomposition is essential for LLM agents as it allows them to:\\n\\n* Handle complex tasks more efficiently\\n* Improve the quality of final results\\n* Refine their approach through self-reflection and self-criticism\\n* Learn from mistakes and adapt to new situations\\n\\nBy decomposing complex tasks into smaller sub-tasks, LLM agents can better understand the requirements of the task, identify potential roadblocks, and develop a more effective plan to achieve the desired outcome.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# Response prompt \n",
    "response_prompt_template = \"\"\"You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\n",
    "\n",
    "# {normal_context}\n",
    "# {step_back_context}\n",
    "\n",
    "# Original Question: {question}\n",
    "# Answer:\"\"\"\n",
    "response_prompt = ChatPromptTemplate.from_template(response_prompt_template)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        # Retrieve context using the normal question\n",
    "        \"normal_context\": RunnableLambda(lambda x: x[\"question\"]) | retriever,\n",
    "        # Retrieve context using the step-back question\n",
    "        \"step_back_context\": generate_queries_step_back | retriever,\n",
    "        # Pass on the question\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "    }\n",
    "    | response_prompt\n",
    "    | ChatGroq(model=\"llama-3.3-70b-versatile\", temperature=0)\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06464db3",
   "metadata": {},
   "source": [
    "# Part 9: HyDE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30546147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f14ff439",
   "metadata": {},
   "source": [
    "![Alt text](hyde.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0784d2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Task decomposition is a crucial paradigm in the development and deployment of Large Language Model (LLM) agents, enabling these artificial intelligence systems to tackle complex tasks by breaking them down into manageable, simpler sub-tasks. This approach is rooted in the understanding that many complex tasks, which might initially seem insurmountable for an LLM due to their intricacy or the vast amount of knowledge required, can be decomposed into a series of simpler, more straightforward tasks. Each of these sub-tasks can then be addressed individually by the LLM, leveraging its strengths in processing and generating human-like language to produce coherent and relevant outputs.\\n\\nThe process of task decomposition for LLM agents involves several key steps. First, the complex task at hand is analyzed to identify its constituent parts or sub-tasks. This analysis requires a deep understanding of the task's requirements, the context in which it is being performed, and the capabilities and limitations of the LLM. Once the sub-tasks are identified, they are prioritized and sequenced in a manner that optimizes the efficiency and effectiveness of the LLM's processing. This sequencing may involve determining the order in which sub-tasks should be executed, identifying any dependencies between them, and allocating the necessary computational resources.\\n\\nTask decomposition not only enhances the performance of LLM agents by making complex tasks more manageable but also facilitates the integration of domain-specific knowledge and expertise. By breaking down tasks into components that can be addressed by specialized modules or knowledge bases, LLMs can leverage external resources and human oversight to ensure the accuracy and relevance of their outputs. Furthermore, this approach enables the development of more transparent and explainable AI systems, as the decomposition of tasks into simpler components can provide insights into the decision-making processes of the LLM.\\n\\nIn conclusion, task decomposition is a powerful strategy for enhancing the capabilities of LLM agents, allowing them to tackle complex tasks with greater precision and effectiveness. By decomposing tasks into simpler sub-tasks, LLMs can leverage their language processing capabilities to produce high-quality outputs, while also facilitating the integration of domain-specific knowledge and promoting transparency and explainability in AI decision-making processes. As the field of natural language processing continues to evolve, the role of task decomposition in the development of sophisticated LLM agents is likely to become increasingly important.\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# HyDE document genration\n",
    "template = \"\"\"Please write a scientific paper passage to answer the question\n",
    "Question: {question}\n",
    "Passage:\"\"\"\n",
    "prompt_hyde = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "generate_docs_for_retrieval = (\n",
    "    prompt_hyde | ChatGroq(model=\"llama-3.3-70b-versatile\", temperature=0)|StrOutputParser()\n",
    ")\n",
    "\n",
    "# Run\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "generate_docs_for_retrieval.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80fb96cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='7c85a6a5-05a0-48ef-809e-fe7f56a5c7cb', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'),\n",
       " Document(id='4f1bda5a-0f22-4971-a694-defdbb5b5c1b', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'),\n",
       " Document(id='31eb3d4d-b54d-4288-99d8-3f099a20a53a', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.'),\n",
       " Document(id='c339ca55-9d9a-4f6c-b41b-3f6ad17ed0de', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Or\\n@article{weng2023agent,\\n  title   = \"LLM-powered Autonomous Agents\",\\n  author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. “Chain of thought prompting elicits reasoning in large language models.” NeurIPS 2022\\n[2] Yao et al. “Tree of Thoughts: Dliberate Problem Solving with Large Language Models.” arXiv preprint arXiv:2305.10601 (2023).\\n[3] Liu et al. “Chain of Hindsight Aligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. “LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve\n",
    "retrieval_chain = generate_docs_for_retrieval | retriever \n",
    "retireved_docs = retrieval_chain.invoke({\"question\":question})\n",
    "retireved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55a2fcb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex tasks into smaller, manageable subgoals or steps. This is a crucial component of planning in LLM-powered autonomous agent systems, as it enables the agent to efficiently handle complex tasks.\\n\\nTask decomposition can be achieved through various methods, including:\\n\\n1. Simple prompting: The LLM can be prompted with questions like \"Steps for XYZ\" or \"What are the subgoals for achieving XYZ?\" to decompose a task into smaller steps.\\n2. Task-specific instructions: The LLM can be provided with task-specific instructions, such as \"Write a story outline\" for writing a novel.\\n3. Human inputs: Humans can provide input to help the LLM decompose a task into smaller steps.\\n4. Chain of Thought (CoT) prompting: This technique involves instructing the LLM to \"think step by step\" to utilize more test-time computation to decompose hard tasks into smaller and simpler steps.\\n5. Tree of Thoughts: This method extends CoT by exploring multiple reasoning possibilities at each step, creating a tree structure of thoughts.\\n\\nTask decomposition is essential for LLM agents as it allows them to plan and execute complex tasks more effectively. However, challenges remain, such as planning over a lengthy history and effectively exploring the solution space, which can be limited by the LLM\\'s context capacity and reliability of natural language interface.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"context\":retireved_docs,\"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e731ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
